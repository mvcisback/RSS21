\section{ERCI as multi-objective optimization}\label{sec:convex}
As may already be apparent to the reader, there is a natural trade off
between probability of generating paths in $\varphi$ (from here
onwards: \emph{the performance}) and causal entropy induced by a
policy (from here onwards: \emph{the randomization}).  In particular,
we are interested in understanding the combinations of $\scthreshold$
and $\randomness$ that allow to solve the (core) ERCI problem. To this
end, we cast ERCI as a variant of multi-objective optimization and
studying its Pareto Front.

% It is convenient to consider this geometrically.
To begin, given a fixed ERCI instance, observe that a scheduler $\sched$
induces a point $x_\sched$:
\begin{equation}
  x_\sched \eqdef \Big\langle \Pr(X_\varphi \mid \sched), H(\sched) \Big\rangle \in [0,1] \times [0,\infty).  
\end{equation}
To ease notation, for $x_\sched = \langle \scp,\rndp \rangle$ we use
$\scp_\sched \eqdef \scp$ and $\rndp_\sched \eqdef \rndp$. Next, we
partially order these points via the standard product ordering:
\begin{equation}
  \langle \scp,\rndp \rangle \leq \langle \scp',\rndp' \rangle \implies \scp \leq \scp' \wedge \rndp \leq \rndp'.
\end{equation}

We say that $\pOneSched$ \emph{guarantees} a point $x_\pOne \eqdef
\langle \scp, \rndp \rangle$, if for every policy $\pTwoSched$, using
$\sched = \langle \pOneSched, \pTwoSched \rangle$, we have
$\scp_\sched \geq \scp$ and $\rndp_\sched \geq \rndp$. Thus, a point
is guaranteed if no matter what policy $\pTwo$ uses, $x_\sched$ will
induce a point no worse w.r.t.\ to either randomization or performance
than $x_\pOne$. Furthermore, observe that guaranteed points are
downward closed, i.e., if $\pOneSched$ guarantees $x$ and $x' \leq x$,
then $\pOneSched$ guarantees $x'$.

\begin{example}
	
\end{example}

We then define the following elementary sets: For any $\pOneSched$,
that $\pOneSched$ guarantees $\langle \scp, \rndp \rangle$, we define
the set of guaranteed points:
\begin{equation}\label{eq:guaranteed}
  \solutions[\pOneSched] \eqdef \{ \langle \scp, \rndp \rangle \mid  \pOneSched \text{ guarantees } \langle \scp, \rndp \rangle \}.
\end{equation}

Any point that can be guaranteed by some $\pOneSched$ is called
\emph{achievable}, i.e., the achievable points are: $ \solutions =
\bigcup_{\pOneSched} \solutions[\pOneSched]$.  Importantly, it holds
that the ERCI problem is satisfiable iff $\langle \scthreshold,
\randomness \rangle$ is achievable.  \sj{We should clarify satisfiable
lingo} Thus, to solve ERCI instances, we start by characterizing
$\solutions$.


\begin{proposition}
  The set of achievable points, $\solutions$, is convex. 
\end{proposition}
\begin{proof}[Proof Sketch]
  Recall that a set is convex, if it is closed under
  convex-combinations\footnotemark. Consider two points
  $\langle \scp, \rndp \rangle, \langle \scp', \rndp' \rangle \in
  \solutions$ achieved by $\pOneSched$ and $\pOneSchedPrime$
  resp. Consider the new policy, $\pi$, defined by employing
  $\pOneSched$ with probability $q$ and $\pOneSchedPrime$ with
  probability $\bar{q} \eqdef 1 - q$.  Because each policy
  \emph{guarantees} its corresponding performance, this new policy as
  performance at least $q\cdot \scp + \bar{q}\cdot \scp'$.  Similarly,
  by viewing $\pi$ as a random variable and applying chain rule
  yields,
  \begin{equation}
    \begin{split}
      H_\tau(\sigma)
      \geq &~q \cdot H( \rv{A}^{\pOne}_{1:\tau'} \mid\mid \rv{S}_{1:\tau} \mid \pi=\pOneSched)~+\\
      &~\bar{q}  \cdot H( \rv{A}^{\pOne}_{1:\tau'} \mid\mid \rv{S}_{1:\tau} \mid \pi=\pOneSchedPrime)\\
      =&~q\cdot\rndp + \bar{q}\cdot \rndp'.
    \end{split}
  \end{equation}
  Thus, any convex combination of guaranteed points is guaranteed by
  a convex combination of the resp. ego policies.
\end{proof}
\footnotetext{
  That is, $y, y' \in Y$ implies for
  every $w \in [0,1]$ that $w \cdot y + (1-w) \cdot y \in Y$
}

Next, observe that because $\solutions$ is downward closed, it
suffices to study the ``maximal'' or non-dominated points.  Precisely,
we say that a point $x$ is \emph{dominated} by $x'$, written $x \prec
x'$, if $x'$ is strictly larger in at least one dimension and not
smaller in the other, i.e., 
\begin{equation}
x \prec x' \iff x \leq x' \wedge x \neq x'.
\end{equation}
The Pareto-front $\pareto{\solutions}$ of $\solutions$ is then the set of non-dominated guaranteed points,
\begin{equation}
  \pareto{\solutions} \eqdef \{ x \in \solutions \mid \forall x' \in \solutions, x \not\prec x'  \}.  
\end{equation}
\noindent
\begin{mdframed}
Importantly, it holds that the ERCI problem is satisfiable iff there exists a  $x \in \pareto{\solutions}$ such that $\langle \scthreshold, \randomness \rangle \prec x$.    
\end{mdframed}

\noindent
Thus the approximating the Pareto-front gives a natural approximation
scheme for ERCI instances. Namely, for any subset $\pareto{} \subseteq
\pareto{\solutions}$,
\begin{enumerate}
\item If there exists an $x \in \pareto{}$ such that
$\langle \scthreshold, \randomness \rangle \prec x$, then the ERCI
Problem must be satisfiable.
\item If there exists an $x \in \pareto{}$
such that $x \prec \langle \scthreshold, \randomness \rangle$ then the
ERCI problem is not satisfiable.
\end{enumerate}

\begin{example}
	
\end{example}

Thus a key algorithmic question in ERCI is how to efficiently explore
and approximate the $\pareto{\solutions}$.  
To this end, we note that while $\solutions$ is defined as a subset of $[0,1] \times [0,\infty)$, we can restrict ourselves to the domain in which we can actually trade performance for randomness. 
We define 
$\rndopt \eqdef \max \{ \rndp \mid \exists \scp \text{ s.t. } \langle \scp, \rndp \rangle \in \solutions  \} $, i.e., the largest randomness that can be guaranteed by any $\pOne$-policy. 
Likewise, we define 
$\scopt \eqdef \max \{ \scp \mid \exists \rndp \text{ s.t. } \langle \scp, \rndp \rangle \in \solutions  \} $, i.e., the largest performance that can be guaranteed by any $\pOne$-policy. 
Then, we define 
$\scmin \eqdef \max \{ \scp \mid \langle \scp, \rndopt \rangle  \in \solutions \}$, the best performance that $\pOne$ can guarantee while guaranteeing optimal randomness. 
Likewise, we define  the analogous $\rndmin \eqdef \max \{ \scp \mid \langle \scp, \rndopt \rangle  \in \solutions \}$.
We thus obtain two points on the Pareto-curve: $\langle \scmin, \rndopt \rangle$ and $\langle \scopt, \rndmin \rangle$, and intuitively, we can trade between these two points following the Pareto curve.

\begin{remark}[Regret Based ERCI]
  In practice, rather that fixing $\scthreshold$ and $\randomness$ a
  priori, one seeks achieve some percentage of the achievable soft
  constraint or causal entropy measure.  In such cases, we
  re-parameterized the ERCI instance with:
  \begin{equation}
    \scthreshold(\epsilon) \eqdef \epsilon \cdot \scopt
    \hspace{3em}
    \randomness(\delta) \eqdef  \delta \cdot \rndopt
  \end{equation}
  where $\epsilon, \delta \in [0, 1]$. As we shall later see, these maximum quantities are
  directly computed in our proposed algorithm.
\end{remark}

Finally, it is helpful to think about the Pareto-curve as a function
in $\rndp$.  We define a characteristic function which given a target
performance ratio, $\epsilon$, yields the optimal randomness ratio,
$\delta$:
\begin{equation}
  \begin{split}
    & \solfuncp\colon [0,1] \rightarrow [0, 1]    \\
    & \solfuncp(\delta) = \max_\epsilon \{ \rndp(\delta) \mid \langle
    \scp(\epsilon), \rndp(\delta) \rangle \in \solutions \} 
  \end{split}
\end{equation}
\begin{proposition}\label{prop:monotone}
  $\solfuncp$ is smooth and (strictly) monotonically decreasing.
\end{proposition}
In particular, the set is \emph{not} a finite polytope, but can be
well approximated by one. We shall however post-pone the proof of
\propref{monotone} until Sec ?. For now, one case observe that
(non-strict) monotone decreasing follows directly from convexity and
using the adequate domains.


With these facts, we are now well-equiped to develop the algorithms in Sec.~\ref{sec:mdps} for MDPs and Sec.~\ref{sec:sgs} for SGs.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
