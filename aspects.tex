\section{ERCI as multi-objective optimization}\label{sec:convex}
\subsection{Preprocessing}
To ease the technical exposition, without loss of generality, we make
the following assumptions:
We assume the graph
structure underlying the SG is finite and acyclic -- and thus all paths
are finite length. When considering $\tau$-bounded path properties (monitorable by finite automata),
this assumption is naturally realized by a $\tau$-step unrolling of a
monitor augmented SG \footnotemark, i.e., augmenting the state space with a counter from $0$ to $\tau$ and the current property monitor state.

\footnotetext{
One may then represent this unrolled graph as a binary
decision diagram, resulting in a (typically) concise graph that grows
proportional to the horizon and minimal state space augmentation
required~\cite{DBLP:conf/cav/Vazquez-Chanlatte20}.}

Next, in order to ensure the hard constraint, $\hard$, we
calculate all states from which the $\pTwo$-player can enforce
violating the hard constraint. Such states are identifiable using a single
topologically ordered pass over $\sg$ from the leaves to the root.  We remove
such states along with their in- and outgoing transitions. Any
$\pOne$-policy now satisfies the hard constraint. 
The remaining sink states are all merged into two states $\target$ and
$\sink$, based on membership in $\soft$, i.e.,
\begin{equation}
  \begin{split}
    \last{\path} = \target ~\implies~ \path \in \soft\\
    \last{\path} = \sink ~\implies~ \path \notin \soft
  \end{split}.
\end{equation}

\begin{example}
	In Fig.~\ref{fig:minimal:mdp} we show a (deterministic) MDP and we plot for all schedulers the induced probability to reach $\target$ and the induced causal entropy, in Fig.~\ref{fig:minimal:soft} and \ref{fig:minimal:entropy}, respectively. 
	We see that taking action $a$ with increasing probability yields obviously to a larger probability to reach $\target$, whereas taking action $a$ and $b$ uniformly at random is optimal for the entropy. 
\end{example}


\begin{figure}
\centering
\begin{subfigure}{0.24\columnwidth}
\centering
\begin{tikzpicture}	
	\node[sstate,initial, initial text=] (si) {$s_0$};
	\node[tstate,above=0.6cm of si] (s0) {$\target$};
	\node[tstate,below=0.6cm of si] (s1) {$\sink$};
	\draw[->] (si) -- node[right] {$a$} (s0);
	\draw[->] (si) -- node[right] {$b$} (s1);
	
\end{tikzpicture}
\caption{Minimal MDP}
\label{fig:minimal:mdp}
\end{subfigure}
\begin{subfigure}{0.36\columnwidth}
\centering
\begin{tikzpicture}[scale=2]
 \draw[->] (-0.05, 0) -- (1, 0) node[below]{$\sched(a \mid s_0 )$};
  	\draw[->] (0, -0.05) -- (0, 0.8) node[above] {$\Pr( \varphi \mid \sched)$};
  	%\draw[-,dashed] (0.4,0) -- (0.4,0.5184);
  	%\draw[-,dashed] (0.0,0.5184) -- (0.4,0.5184);
  \draw[ domain=0:0.8, smooth, variable=\x, blue] plot ({\x}, {\x});
\end{tikzpicture}
\caption{Probability to reach $\target$}
\label{fig:minimal:soft}
\end{subfigure}
\begin{subfigure}{0.36\columnwidth}
\centering
\begin{tikzpicture}[scale=2]	
 \draw[->] (-0.05, 0) -- (1, 0) node[below]{$\sched(a \mid s_0 )$};
  	\draw[->] (0, -0.05) -- (0, 0.8) node[above] {$H(\sched)$};
  	%\draw[-,dashed] (0.4,0) -- (0.4,0.5184);
  	%\draw[-,dashed] (0.0,0.5184) -- (0.4,0.5184);
  \draw[ domain=0.001:0.999, smooth, variable=\x, blue] plot ({\x}, {-\x * ln(\x) - (1 - \x)*  ln(1-\x)});
\end{tikzpicture}
\caption{Causal Entropy}
\label{fig:minimal:entropy}
\end{subfigure}

\caption{Minimal ERCI problem with $\varphi = ( \last{\xi} = \target )$}
\end{figure}

\input{geometric}
\subsection{Geometric Perspective}
There is a natural trade-off
between probability of generating paths in $\varphi$ (from here
onwards: \emph{the performance}) and causal entropy induced by a
policy (\emph{the randomization}).  In particular, with all other ingredients fixed, 
we are interested in understanding the combinations of $\scthreshold$
and $\randomness$ that yield a solvable instance of the (core) ERCI problem. To this
end, we cast ERCI as an instance of a multi-objective optimization problem, and
study its Pareto front. Some ideas are inspired by variants of multi-objective analysis of MDPs with multiple soft constraints, e.g.~\cite{DBLP:conf/stacs/ChatterjeeMH06,DBLP:conf/tacas/EtessamiKVY07}.

It is convenient to consider this front geometrically.
To begin, given a fixed ERCI instance, a scheduler $\sched$
\emph{induces} a point $x_\sched$:
\begin{equation}
  x_\sched \eqdef \Big\langle \Pr(X_\varphi \mid \sched), H(\sched) \Big\rangle \in [0,1] \times [0,\infty).  
\end{equation}
To ease notation, for $x_\sched = \langle \scp,\rndp \rangle$ we use
$\scp_\sched \eqdef \scp$ and $\rndp_\sched \eqdef \rndp$. Next, we
partially order these points via the standard product ordering:
\begin{equation}
  \langle \scp,\rndp \rangle \preceq \langle \scp',\rndp' \rangle \quad\text{ iff }\quad \scp \leq \scp' \wedge \rndp \leq \rndp'.
\end{equation}

We say that $\pOneSched$ \emph{guarantees} a point $x_\pOne \eqdef
\langle \scp, \rndp \rangle$, if for every policy $\pTwoSched$, using
$\sched = \langle \pOneSched, \pTwoSched \rangle$, we have
$\scp_\sched \geq \scp$ and $\rndp_\sched \geq \rndp$. Thus, a point
is guaranteed if no matter what policy $\pTwo$ uses, $x_\sched$ will
induce a point no worse w.r.t.\ to either randomization or performance
than $x_\pOne$. 
We define
\emph{the set of guaranteed points} for a scheduler $\pOneSched$:
\begin{equation}\label{eq:guaranteed}
  \solutions[\pOneSched] \eqdef \{ \langle \scp, \rndp \rangle \mid  \pOneSched \text{ guarantees } \langle \scp, \rndp \rangle \}.
\end{equation}
We observe that guaranteed points are
downward closed, i.e., if $\pOneSched$ guarantees $x$ and $x' \preceq x$,
then $\pOneSched$ guarantees $x'$.
\begin{example}
Consider Fig.~\ref{fig:geom:guarantee}. We fix $\pOneSched$ and in the blue hatched area draw all points induced by $\sched = \langle \pOneSched, \pTwoSched \rangle$ when varying $\pTwoSched$. We take the minimal randomness $\rndp$ and the minimal performance $\scp$. The points in the downward closure  of $\langle \scp, \rndp \rangle$ (green circle) are the guaranteed points for $\pOneSched$ in the green solid area.	
We notice the gap between both areas: While the performance and randomization may be better than the optimum that $\pOne$ can guarantee, it cannot guarantee a higher randomization \emph{and} performance simultaneously, as  the $\pTwo$-player would have a counter-policy violating either the performance \emph{or} the randomization.
\end{example}

Points guaranteed by some $\pOneSched$ are called
\emph{achievable}. Thus, the achievable points are: $ \solutions =
\bigcup_{\pOneSched} \solutions[\pOneSched]$.  Importantly, the ERCI problem is realizable iff $\langle \scthreshold,
\randomness \rangle$ is achievable. 
Thus, to solve ERCI instances, we start by characterizing
$\solutions$. We start by observing the $\solutions$ is convex\footnotemark~(proof in Sec~\ref{sec:proofs}).


\begin{proposition}\label{prop:convex}
  The set of achievable points, $\solutions$, is convex. 
\end{proposition}

\footnotetext{
  That is, $x, x' \in \solutions$ implies for
  every $w \in [0,1]$ that $w \cdot x + (1-w) \cdot x \in \solutions$
}

Next, because $\solutions$ is downward closed, it
suffices to study the ``maximal'' or non-dominated points.  Precisely,
we say that a point $x$ is \emph{dominated} by $x'$ if $x \prec
x'$, i.e., if $x \preceq x' \wedge x \neq x'$.
The Pareto front $\pareto{\solutions}$ of $\solutions$ is then the set of non-dominated achievable  points,
\begin{equation}
  \pareto{\solutions} \eqdef \{ x \in \solutions \mid \forall x' \in \solutions, x \not\prec x'  \}.  
\end{equation}
\noindent
\begin{mdframed}
Importantly, it holds that the ERCI problem is satisfiable iff there exists a  $x \in \pareto{\solutions}$ such that $\langle \scthreshold, \randomness \rangle \preceq x$.    
\end{mdframed}
\begin{example}
	The set $\solutions$ illustrated in Fig.~\ref{fig:geom:solution} is obtained by taking the union of guaranteed points, and can be characterized by the set of points on the Pareto front: This is the curved border between the green and white area, in particular the three green dots are on the Pareto front. Any ERCI instance with $\langle \scthreshold, \randomness \rangle$ in the green area is realizable.
\end{example}


\noindent
Approximating the Pareto front gives a natural approximation
scheme for ERCI instances: For any subset $\pareto{} \subseteq
\pareto{\solutions}$,
\begin{enumerate}
\item If there exists an $x \in \pareto{}$ such that
$\langle \scthreshold, \randomness \rangle \preceq x$, then the ERCI
Problem must be realizable, $x$ is a witness to realizability.
\item If there exists an $x \in \pareto{}$
such that $x \prec \langle \scthreshold, \randomness \rangle$ then the
ERCI problem is not realizable, and $x$ is a witness to unrealizability.
\end{enumerate}
Due to convexity, we may speed up the search for realizability: If there exist $x_1, x_2 \in \pareto{}$ such that $\langle \scthreshold, \randomness \rangle \prec \big(w \cdot x_1 + (1-w) \cdot x_2\big)$, we call $x_1,x_2$ a witness-pair.

\begin{example}
\label{ex:approximation}
	Consider Fig.~\ref{fig:geom:iterative}. We have found three points on the Pareto front, and already have a good impression of the trade-off between randomization and performance. In particular, the green area is definitively a subset of $\solutions$: It exploits the downward closure and the convexity of $\solutions$. The red (dotted) part contain the points on the Pareto front in their downward closure, thus they cannot be part of the Pareto front themselves.
	Furthermore, the topmost point on the Pareto front was obtained by maximizing performance (and optimizing randomization only as a secondary objective). Thus, by construction, the bricked area at the top is not realizable. Analogously, the bricked area at the right reflects non-achievable randomization. 
\end{example}

Thus a key algorithmic question in ERCI is how to efficiently explore
and approximate the Pareto front $\pareto{\solutions}$. As first steps, we find the two special points induced by (1) optimizing performance and only then randomization (the topmost green point in the figures) and (2) optimizing randomization and only then performance (the rightmost green point). 
As we have seen, these restrict the domain in which we can actually trade performance for randomness. 
We define 
$\rndopt \eqdef \max \{ \rndp \mid \exists \scp \text{ s.t. } \langle \scp, \rndp \rangle \in \solutions  \} $, i.e., the largest randomness that can be guaranteed by any $\pOne$-policy. 
Likewise, we define 
$\scopt \eqdef \max \{ \scp \mid \exists \rndp \text{ s.t. } \langle \scp, \rndp \rangle \in \solutions  \} $, i.e., the largest performance that can be guaranteed by any $\pOne$-policy. 
Then, we define 
$\scmin \eqdef \max \{ \scp \mid \langle \scp, \rndopt \rangle  \in \solutions \}$, the best performance that $\pOne$ can guarantee while guaranteeing optimal randomness. 
Likewise, we define  the analogous $\rndmin \eqdef \max \{ \scp \mid \langle \scp, \rndopt \rangle  \in \solutions \}$.
We thus obtain two points on the Pareto front: $\langle \scmin, \rndopt \rangle$ and $\langle \scopt, \rndmin \rangle$, and intuitively, we can trade between these two points following the Pareto front.

%\begin{remark}[Regret Based ERCI]
\subsection{Regret Based ERCI}
Often, rather that fixing $\scthreshold$ and $\randomness$ a
  priori, one seeks to guarantee some percentage of the independently achievable soft
  constraint and causal entropy measure.  We
  re-parameterize ERCI as follows:
  \begin{equation}
    \scthreshold_\epsilon \eqdef \epsilon \cdot (\scopt - \scmin) + \scmin
    \hspace{1em}
    \randomness_\delta \eqdef  \delta \cdot (\rndopt - \rndmin) + \rndmin
  \end{equation}
  where $\epsilon, \delta \in [0, 1]$. We call this version of ERCI \emph{regret-based}. Geometrically, after computing $\scopt$ and $\rndopt$, we know that the left triangle in Fig.~\ref{fig:geom:regret} is definitively realizable, and the regret-based ERCI asks whether the white circle is also realizable (where the point of the white point is given by $\epsilon$ and $\delta$. %As we shall later see, these maximum quantities are
 % directly computed in our proposed algorithm. 
%\end{remark}
\noindent 
Together, we obtain the following (core) ERCI problem.
\begin{mdframed}[backgroundcolor=blue!5,nobreak=true]
\textbf{The Core ERCI Problem}:
Given an finite acyclic SG $\sg$, with sink states, $\target$ and $\sink$, and thresholds $\epsilon, \delta \in [0,1]$,  find a $\pOne$-policy $\pOneSched$  such that for every $\pTwo$-policy $\pTwoSched$:
\begin{enumerate}
\item (\emph{soft constraint)}
  $\Pr(\last{\xi} = \target \mid \sched) \geq \scthreshold_\epsilon$
\item (\emph{randomness constraint}) $H(\sigma) \geq \randomness_\delta$
\end{enumerate}
where  $\sched = \langle \pOneSched, \pTwoSched \rangle$.
\end{mdframed}


Finally, it is helpful to think about the Pareto front as a function of randomization in this reparameterization.  We define a characteristic function which given a target
performance ratio, $\epsilon$, yields the optimal randomness ratio,
$\delta$:
\begin{equation}
  \begin{split}
    & \solfuncp\colon [0,1] \rightarrow [0, 1]    \\
    & \solfuncp(\delta) = \max_\epsilon \{ \randomness_\delta \mid \langle
    \scthreshold_\epsilon, \randomness_\delta \rangle \in \solutions \} 
  \end{split}
\end{equation}
\begin{proposition}\label{prop:monotone}
  $\solfuncp$ is continuous and (strictly) decreasing.
\end{proposition}
 We shall temporarily postpone the proof of
\propref{monotone}. For now, one case observe that
(non-strict) monotone decreasing follows directly from convexity and
using the adequate domains.
Finally, the set  $\solutions$ is (in general) \emph{not} a finite polytope -- the MDP in Fig.~\ref{fig:minimal:mdp} serves as an example. Nevertheless,  $\solutions$ can be well approximated with finitely many vertices, see Ex.~\ref{ex:approximation}.

With these facts, we are now well-equipped to develop the algorithms in Sec.~\ref{sec:mdps} for MDPs and Sec.~\ref{sec:sgs} for SGs.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
